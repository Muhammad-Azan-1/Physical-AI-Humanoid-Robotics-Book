"use strict";(globalThis.webpackChunkphysical_ai_book=globalThis.webpackChunkphysical_ai_book||[]).push([[3026],{1062:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>u,contentTitle:()=>c,default:()=>p,frontMatter:()=>l,metadata:()=>i,toc:()=>d});const i=JSON.parse('{"id":"module4/week11-13","title":"Weeks 11-13: Humanoid Development & VLA","description":"Part 1: Humanoid Robot Development (Weeks 11-12)","source":"@site/docs/module4/week11-13.md","sourceDirName":"module4","slug":"/module4/week11-13","permalink":"/Physical-AI-Humanoid-Robotics-Book/docs/module4/week11-13","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{"id":"week11-13","title":"Weeks 11-13: Humanoid Development & VLA","sidebar_label":"Weeks 11-13: Humanoid & VLA"},"sidebar":"mainSidebar","previous":{"title":"Overview","permalink":"/Physical-AI-Humanoid-Robotics-Book/docs/module4"}}');var r=t(4848),o=t(8453),s=t(1470),a=t(9365);const l={id:"week11-13",title:"Weeks 11-13: Humanoid Development & VLA",sidebar_label:"Weeks 11-13: Humanoid & VLA"},c="Weeks 11-13: Humanoid Development & VLA",u={},d=[{value:"Part 1: Humanoid Robot Development (Weeks 11-12)",id:"part-1-humanoid-robot-development-weeks-11-12",level:2},{value:"The Inverted Pendulum Problem",id:"the-inverted-pendulum-problem",level:3},{value:"Kinematics: Forward vs. Inverse",id:"kinematics-forward-vs-inverse",level:3},{value:"Part 2: The Cognitive Brain (Week 13)",id:"part-2-the-cognitive-brain-week-13",level:2},{value:"Step 1: Hearing (OpenAI Whisper)",id:"step-1-hearing-openai-whisper",level:3},{value:"Step 2: Thinking (LLM Planning)",id:"step-2-thinking-llm-planning",level:3},{value:"Step 3: Acting (ROS 2 Action Client)",id:"step-3-acting-ros-2-action-client",level:3},{value:"The Capstone: The Autonomous Humanoid",id:"the-capstone-the-autonomous-humanoid",level:2},{value:"Summary: Humanoid &amp; VLA",id:"summary-humanoid--vla",level:2},{value:"Key Technologies",id:"key-technologies",level:3},{value:"The &quot;Sim-to-Real&quot; Challenge",id:"the-sim-to-real-challenge",level:3}];function h(e){const n={blockquote:"blockquote",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,o.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"weeks-11-13-humanoid-development--vla",children:"Weeks 11-13: Humanoid Development & VLA"})}),"\n",(0,r.jsxs)(s.A,{children:[(0,r.jsxs)(a.A,{value:"full",label:"Full Content",default:!0,children:[(0,r.jsx)(n.h2,{id:"part-1-humanoid-robot-development-weeks-11-12",children:"Part 1: Humanoid Robot Development (Weeks 11-12)"}),(0,r.jsx)(n.p,{children:"Building a humanoid is the ultimate engineering challenge. It requires mastering the physics of instability."}),(0,r.jsx)(n.h3,{id:"the-inverted-pendulum-problem",children:"The Inverted Pendulum Problem"}),(0,r.jsx)(n.p,{children:"A walking human is essentially an inverted pendulum that is constantly falling and catching itself."}),(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"ZMP (Zero Moment Point):"})," The traditional control theory approach. We calculate the point where the total inertial force is zero and ensure it stays within the support polygon (the feet)."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Reinforcement Learning (RL):"}),' The modern approach. We let the robot "play" in simulation (Isaac Lab) millions of times until it learns to walk.']}),"\n"]}),(0,r.jsxs)(n.blockquote,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Case Study: Unitree G1"}),"\nThe Unitree G1 uses a hybrid approach. It has high-torque motors (up to 120Nm) and runs a policy trained in Isaac Gym using ",(0,r.jsx)(n.strong,{children:"PPO (Proximal Policy Optimization)"}),". This allows it to recover from pushes and walk on uneven terrain."]}),"\n"]}),(0,r.jsx)(n.h3,{id:"kinematics-forward-vs-inverse",children:"Kinematics: Forward vs. Inverse"}),(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Forward Kinematics (FK):"}),' "If I set my joint angles to X, where is my hand?" (Easy).']}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Inverse Kinematics (IK):"}),' "I want my hand at position Y, what should my joint angles be?" (Hard).',"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["For humanoids, IK is computationally expensive because they have high Degrees of Freedom (DoF). We use solvers like ",(0,r.jsx)(n.strong,{children:"Pinocchio"})," or ",(0,r.jsx)(n.strong,{children:"KDL"})," within ROS 2."]}),"\n"]}),"\n"]}),"\n"]}),(0,r.jsx)(n.hr,{}),(0,r.jsx)(n.h2,{id:"part-2-the-cognitive-brain-week-13",children:"Part 2: The Cognitive Brain (Week 13)"}),(0,r.jsxs)(n.p,{children:["Now that our robot can walk, let's give it a mind. We will build a ",(0,r.jsx)(n.strong,{children:"VLA (Vision-Language-Action)"})," pipeline."]}),(0,r.jsx)(n.h3,{id:"step-1-hearing-openai-whisper",children:"Step 1: Hearing (OpenAI Whisper)"}),(0,r.jsx)(n.p,{children:"We need to convert audio waves into text."}),(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Python Code: ROS 2 Whisper Node"})}),(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'import rclpy\nfrom rclpy.node import Node\nfrom std_msgs.msg import String\nimport whisper\nimport speech_recognition as sr\n\nclass WhisperNode(Node):\n    def __init__(self):\n        super().__init__(\'whisper_node\')\n        self.publisher_ = self.create_publisher(String, \'/human/voice_command\', 10)\n        self.model = whisper.load_model("base")\n        self.recognizer = sr.Recognizer()\n        self.timer = self.create_timer(0.1, self.listen_and_transcribe)\n\n    def listen_and_transcribe(self):\n        with sr.Microphone() as source:\n            # Listen for audio (blocking for simplicity)\n            audio = self.recognizer.listen(source)\n            try:\n                # Save to temp file and transcribe\n                with open("temp.wav", "wb") as f:\n                    f.write(audio.get_wav_data())\n                result = self.model.transcribe("temp.wav")\n                text = result["text"]\n                \n                msg = String()\n                msg.data = text\n                self.publisher_.publish(msg)\n                self.get_logger().info(f\'Heard: "{text}"\')\n            except Exception as e:\n                self.get_logger().error(f\'Error: {e}\')\n\ndef main():\n    rclpy.init()\n    node = WhisperNode()\n    rclpy.spin(node)\n    node.destroy_node()\n    rclpy.shutdown()\n'})}),(0,r.jsx)(n.h3,{id:"step-2-thinking-llm-planning",children:"Step 2: Thinking (LLM Planning)"}),(0,r.jsx)(n.p,{children:'We feed the transcribed text into an LLM (like GPT-4o) along with a "System Prompt" that defines the robot\'s capabilities.'}),(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"System Prompt Example:"})}),(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-text",children:'You are a robot assistant. You can perform the following actions:\n1. navigate_to(location)\n2. pick_up(object)\n3. place(object, location)\n\nUser: "Put the apple in the trash."\nPlan:\n1. navigate_to("table")\n2. pick_up("apple")\n3. navigate_to("trash_can")\n4. place("apple", "trash_can")\n'})}),(0,r.jsx)(n.h3,{id:"step-3-acting-ros-2-action-client",children:"Step 3: Acting (ROS 2 Action Client)"}),(0,r.jsx)(n.p,{children:"The LLM outputs a plan (e.g., JSON or a list). We parse this plan and execute it using ROS 2 Action Clients."}),(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Python Code: Action Client"})}),(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"from rclpy.action import ActionClient\nfrom nav2_msgs.action import NavigateToPose\n\nclass RobotBrain(Node):\n    def __init__(self):\n        super().__init__('robot_brain')\n        self._action_client = ActionClient(self, NavigateToPose, 'navigate_to_pose')\n\n    def send_goal(self, x, y):\n        goal_msg = NavigateToPose.Goal()\n        goal_msg.pose.header.frame_id = 'map'\n        goal_msg.pose.pose.position.x = x\n        goal_msg.pose.pose.position.y = y\n        \n        self._action_client.wait_for_server()\n        return self._action_client.send_goal_async(goal_msg)\n"})}),(0,r.jsx)(n.h2,{id:"the-capstone-the-autonomous-humanoid",children:"The Capstone: The Autonomous Humanoid"}),(0,r.jsx)(n.p,{children:"Combine everything!"}),(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Voice Command:"}),' "Go to the kitchen."']}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Whisper:"})," Transcribes audio."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"LLM:"})," Decides to call ",(0,r.jsx)(n.code,{children:'navigate_to("kitchen")'}),"."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Nav2:"})," Plans a path avoiding obstacles."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Locomotion:"})," The RL policy moves the legs to follow the path."]}),"\n"]})]}),(0,r.jsxs)(a.A,{value:"summary",label:"Summary",children:[(0,r.jsx)(n.h2,{id:"summary-humanoid--vla",children:"Summary: Humanoid & VLA"}),(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Goal:"})," A robot that walks like a human and thinks like an AI."]}),(0,r.jsx)(n.h3,{id:"key-technologies",children:"Key Technologies"}),(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Locomotion:"})," RL (PPO) is replacing ZMP for robust walking."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Whisper:"})," Real-time, offline-capable speech recognition."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"LLMs:"}),' The "Prefrontal Cortex" of the robot, enabling high-level planning.']}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"VLA Models:"})," The future\u2014end-to-end models that go directly from pixels/text to motor torques (e.g., Google RT-2)."]}),"\n"]}),(0,r.jsx)(n.h3,{id:"the-sim-to-real-challenge",children:'The "Sim-to-Real" Challenge'}),(0,r.jsxs)(n.p,{children:["Training these cognitive models requires massive data. We use ",(0,r.jsx)(n.strong,{children:"Isaac Sim"}),' to generate synthetic "experiences" for the VLA models before deploying them to the real Unitree G1.']})]})]})]})}function p(e={}){const{wrapper:n}={...(0,o.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(h,{...e})}):h(e)}},1470:(e,n,t)=>{t.d(n,{A:()=>w});var i=t(6540),r=t(4164),o=t(7559),s=t(3104),a=t(6347),l=t(205),c=t(7485),u=t(1682),d=t(679);function h(e){return i.Children.toArray(e).filter(e=>"\n"!==e).map(e=>{if(!e||(0,i.isValidElement)(e)&&function(e){const{props:n}=e;return!!n&&"object"==typeof n&&"value"in n}(e))return e;throw new Error(`Docusaurus error: Bad <Tabs> child <${"string"==typeof e.type?e.type:e.type.name}>: all children of the <Tabs> component should be <TabItem>, and every <TabItem> should have a unique "value" prop.`)})?.filter(Boolean)??[]}function p(e){const{values:n,children:t}=e;return(0,i.useMemo)(()=>{const e=n??function(e){return h(e).map(({props:{value:e,label:n,attributes:t,default:i}})=>({value:e,label:n,attributes:t,default:i}))}(t);return function(e){const n=(0,u.XI)(e,(e,n)=>e.value===n.value);if(n.length>0)throw new Error(`Docusaurus error: Duplicate values "${n.map(e=>e.value).join(", ")}" found in <Tabs>. Every value needs to be unique.`)}(e),e},[n,t])}function m({value:e,tabValues:n}){return n.some(n=>n.value===e)}function g({queryString:e=!1,groupId:n}){const t=(0,a.W6)(),r=function({queryString:e=!1,groupId:n}){if("string"==typeof e)return e;if(!1===e)return null;if(!0===e&&!n)throw new Error('Docusaurus error: The <Tabs> component groupId prop is required if queryString=true, because this value is used as the search param name. You can also provide an explicit value such as queryString="my-search-param".');return n??null}({queryString:e,groupId:n});return[(0,c.aZ)(r),(0,i.useCallback)(e=>{if(!r)return;const n=new URLSearchParams(t.location.search);n.set(r,e),t.replace({...t.location,search:n.toString()})},[r,t])]}function f(e){const{defaultValue:n,queryString:t=!1,groupId:r}=e,o=p(e),[s,a]=(0,i.useState)(()=>function({defaultValue:e,tabValues:n}){if(0===n.length)throw new Error("Docusaurus error: the <Tabs> component requires at least one <TabItem> children component");if(e){if(!m({value:e,tabValues:n}))throw new Error(`Docusaurus error: The <Tabs> has a defaultValue "${e}" but none of its children has the corresponding value. Available values are: ${n.map(e=>e.value).join(", ")}. If you intend to show no default tab, use defaultValue={null} instead.`);return e}const t=n.find(e=>e.default)??n[0];if(!t)throw new Error("Unexpected error: 0 tabValues");return t.value}({defaultValue:n,tabValues:o})),[c,u]=g({queryString:t,groupId:r}),[h,f]=function({groupId:e}){const n=function(e){return e?`docusaurus.tab.${e}`:null}(e),[t,r]=(0,d.Dv)(n);return[t,(0,i.useCallback)(e=>{n&&r.set(e)},[n,r])]}({groupId:r}),v=(()=>{const e=c??h;return m({value:e,tabValues:o})?e:null})();(0,l.A)(()=>{v&&a(v)},[v]);return{selectedValue:s,selectValue:(0,i.useCallback)(e=>{if(!m({value:e,tabValues:o}))throw new Error(`Can't select invalid tab value=${e}`);a(e),u(e),f(e)},[u,f,o]),tabValues:o}}var v=t(2303);const b={tabList:"tabList__CuJ",tabItem:"tabItem_LNqP"};var x=t(4848);function j({className:e,block:n,selectedValue:t,selectValue:i,tabValues:o}){const a=[],{blockElementScrollPositionUntilNextRender:l}=(0,s.a_)(),c=e=>{const n=e.currentTarget,r=a.indexOf(n),s=o[r].value;s!==t&&(l(n),i(s))},u=e=>{let n=null;switch(e.key){case"Enter":c(e);break;case"ArrowRight":{const t=a.indexOf(e.currentTarget)+1;n=a[t]??a[0];break}case"ArrowLeft":{const t=a.indexOf(e.currentTarget)-1;n=a[t]??a[a.length-1];break}}n?.focus()};return(0,x.jsx)("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,r.A)("tabs",{"tabs--block":n},e),children:o.map(({value:e,label:n,attributes:i})=>(0,x.jsx)("li",{role:"tab",tabIndex:t===e?0:-1,"aria-selected":t===e,ref:e=>{a.push(e)},onKeyDown:u,onClick:c,...i,className:(0,r.A)("tabs__item",b.tabItem,i?.className,{"tabs__item--active":t===e}),children:n??e},e))})}function y({lazy:e,children:n,selectedValue:t}){const o=(Array.isArray(n)?n:[n]).filter(Boolean);if(e){const e=o.find(e=>e.props.value===t);return e?(0,i.cloneElement)(e,{className:(0,r.A)("margin-top--md",e.props.className)}):null}return(0,x.jsx)("div",{className:"margin-top--md",children:o.map((e,n)=>(0,i.cloneElement)(e,{key:n,hidden:e.props.value!==t}))})}function _(e){const n=f(e);return(0,x.jsxs)("div",{className:(0,r.A)(o.G.tabs.container,"tabs-container",b.tabList),children:[(0,x.jsx)(j,{...n,...e}),(0,x.jsx)(y,{...n,...e})]})}function w(e){const n=(0,v.A)();return(0,x.jsx)(_,{...e,children:h(e.children)},String(n))}},8453:(e,n,t)=>{t.d(n,{R:()=>s,x:()=>a});var i=t(6540);const r={},o=i.createContext(r);function s(e){const n=i.useContext(o);return i.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:s(e.components),i.createElement(o.Provider,{value:n},e.children)}},9365:(e,n,t)=>{t.d(n,{A:()=>s});t(6540);var i=t(4164);const r={tabItem:"tabItem_Ymn6"};var o=t(4848);function s({children:e,hidden:n,className:t}){return(0,o.jsx)("div",{role:"tabpanel",className:(0,i.A)(r.tabItem,t),hidden:n,children:e})}}}]);